{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "talent-analytics.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ash-netizen/HR-Analytics/blob/main/talent_analytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEcbAEWuULDU"
      },
      "source": [
        "# HR ANALYTICS "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obVpThwoULDZ"
      },
      "source": [
        "## Problem Statement   \n",
        "A large company named АВС, at any given point of time, around 4000 employees. However, every year, around 15% of its employees leave the company and need to be replaced with the talent pool available in the job market. The management believes that this level of attrition (employees leaving, either on their own or because they got fired) is bad for the company, because of the following reasons\n",
        "1. The former employees’ projects get delayed, which makes it difficult to meet timelines, resulting in a reputation loss among consumers and partners\n",
        "1. A sizeable department has to be maintained, for the purposes of recruiting new talent\n",
        "1. More often than not, the new employees have to be trained for the job and/or given time to acclimatise themselves to the company\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "ziN1xDi3ULDs"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "id": "QWvDGhXbULDv"
      },
      "source": [
        "! pip install openpyxl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBTyHekfULDw"
      },
      "source": [
        "# Description of features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hkV7AkfiULDx"
      },
      "source": [
        "description = pd.read_excel('/kaggle/input/hr-analytics-case-study/data_dictionary.xlsx')\n",
        "description.replace(to_replace=np.nan, value=' ', inplace=True)\n",
        "description"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWPF4dmSULDx"
      },
      "source": [
        "# Create main data frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kA-0aSDVULD1"
      },
      "source": [
        "df = pd.read_csv('/kaggle/input/hr-analytics-case-study/general_data.csv')\n",
        "print(df.columns)\n",
        "print(df.shape)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_nNJ9qztULD2"
      },
      "source": [
        "df_1 = pd.read_csv('/kaggle/input/hr-analytics-case-study/manager_survey_data.csv')\n",
        "print(df_1.columns)\n",
        "print(df_1.shape)\n",
        "df_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CywXOOI-ULD2"
      },
      "source": [
        "df_2 = pd.read_csv('/kaggle/input/hr-analytics-case-study/employee_survey_data.csv')\n",
        "print(df_2.columns)\n",
        "print(df_2.shape)\n",
        "df_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhBuFSPXULD3"
      },
      "source": [
        "# Concatenation main DF and Social Metrics DF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "prKc4U8VULD3"
      },
      "source": [
        "df =  pd.concat([df.set_index('EmployeeID'), df_1.set_index('EmployeeID'),df_2.set_index('EmployeeID')], axis=1, join='inner').reset_index()\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdWEGJCuULD5"
      },
      "source": [
        "# Research of DateTime frames and data extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EdPbVkRiULD5"
      },
      "source": [
        "weekends = ['2015-12-25', '2015-10-02', '2015-11-11', '2015-05-01',\n",
        "            '2015-01-14', '2015-11-10', '2015-03-05', '2015-07-17',\n",
        "            '2015-01-26', '2015-11-09', '2015-09-17', '2015-01-01']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "n6fYcSHVULD5"
      },
      "source": [
        "df_in = pd.read_csv('/kaggle/input/hr-analytics-case-study/in_time.csv')\n",
        "df_in.iloc[:,1:] = df_in.iloc[:,1:].astype('datetime64[ns]')\n",
        "df_in.rename({'Unnamed: 0': 'EmployeeID'}, axis=1, inplace=True)\n",
        "df_in.drop(weekends, axis=1, inplace=True)\n",
        "# for col in df_in.columns[1:]:\n",
        "#     df_in[col] = pd.to_datetime(df_in[col]).dt.time\n",
        "print(df_in.shape)\n",
        "df_in[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aItrSZ2SULD6"
      },
      "source": [
        "df_in_hour = pd.DataFrame()\n",
        "for col in df_in.columns[1:]:\n",
        "    time = pd.DatetimeIndex(df_in[col])\n",
        "    df_in_hour[col] = (time.hour * 60 + time.minute)/60\n",
        "\n",
        "df_in_hour[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BMtgU-DaULD6"
      },
      "source": [
        "df_out = pd.read_csv('/kaggle/input/hr-analytics-case-study/out_time.csv')\n",
        "df_out.iloc[:,1:] = df_out.iloc[:,1:].astype('datetime64[ns]')\n",
        "df_out.rename({'Unnamed: 0': 'EmployeeID'}, axis=1, inplace=True)\n",
        "df_out.drop(weekends, axis=1, inplace=True)\n",
        "# for col in df_out.columns[1:]:\n",
        "#     df_out[col] = pd.to_datetime(df_out[col]).dt.time\n",
        "print(df_out.shape)\n",
        "df_out[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2d93TfATULD7"
      },
      "source": [
        "df_out_hour = pd.DataFrame()\n",
        "for col in df_out.columns[1:]:\n",
        "    time = pd.DatetimeIndex(df_out[col])\n",
        "    df_out_hour[col] = (time.hour * 60 + time.minute)/60\n",
        "\n",
        "df_out_hour[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvEcrRq1ULD7"
      },
      "source": [
        "# Create DF for time parameters (later concat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HkP6xqYULD8"
      },
      "source": [
        "### !!! Let's chek inexes from data frames with time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "u7eMZfSnULD8"
      },
      "source": [
        "time_df = pd.DataFrame()\n",
        "time_df['EmployeeID_in'] = df_in['EmployeeID']\n",
        "time_df['EmployeeID_out'] = df_out['EmployeeID']\n",
        "time_df['EmployeeID'] = time_df['EmployeeID_in'] - time_df['EmployeeID_out']\n",
        "not_zero = time_df.loc[time_df['EmployeeID'] != 0]\n",
        "time_df['EmployeeID'] = df_in['EmployeeID']\n",
        "not_zero"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wninsxgFULD9"
      },
      "source": [
        "time_df.drop(['EmployeeID_in','EmployeeID_out'], axis=1, inplace=True)\n",
        "time_df[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Jp2Jib3pULD9"
      },
      "source": [
        "df_in_avg = pd.DataFrame()\n",
        "time_df['in_avg'] = df_in_hour.iloc[:,1:].mean(axis=1)\n",
        "time_df[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SC4RhIQuULD-"
      },
      "source": [
        "df_out_avg = pd.DataFrame()\n",
        "time_df['out_avg'] = df_out_hour.iloc[:,1:].mean(axis=1)\n",
        "time_df[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "A-YjpUu1ULD-"
      },
      "source": [
        "df_out_avg = pd.DataFrame()\n",
        "time_df['avg_work_day'] = time_df['out_avg'] - time_df['in_avg']\n",
        "time_df[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Qkyx2vLzULD-"
      },
      "source": [
        "time_df['num_day_off'] = df_in_hour.isnull().sum(axis=1)\n",
        "time_df[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE2vGTPDULD_"
      },
      "source": [
        "# Concatenation main DF and time parameters DF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4_EEfybkULD_"
      },
      "source": [
        "df =  pd.concat([df.set_index('EmployeeID'), time_df.set_index('EmployeeID')], axis=1, join='inner').reset_index()\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MF4wqiyULEA"
      },
      "source": [
        "# Data cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OID5ChE0ULEA"
      },
      "source": [
        "### Drop useless columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hiBGoY8_ULEA"
      },
      "source": [
        "for el in list(df.columns):\n",
        "    print(f'======================= {el} =======================')\n",
        "    print(df[el].value_counts(dropna=False))\n",
        "    print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_PbNyV4vULEB"
      },
      "source": [
        "# to drop\n",
        "# 'EmployeeCount', 'Over18', 'StandardHours'\n",
        "df.drop(['EmployeeCount', 'Over18', 'StandardHours'], axis=1, inplace=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3Dv_0Nr_ULEB"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxeXDAmVULEC"
      },
      "source": [
        "# NaN cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "woCAdQF6ULEC"
      },
      "source": [
        "def NaN_info(df):\n",
        "    global null_view\n",
        "    try:\n",
        "        null_view = df[[col for col in df.columns if df[col].isna().sum() > 0]].isna().sum().sort_values(ascending = True)\n",
        "        null_view = pd.DataFrame(null_view, columns=['NANs'])\n",
        "        null_view[['PERCENT']] = null_view.NANs.apply(lambda x: round((x/len(df))*100, 2))\n",
        "        null_view[['TYPE']] = df.dtypes\n",
        "    except:\n",
        "        return null_view\n",
        "    return null_view\n",
        "\n",
        "NaN_info(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Q2L1Bji2ULEC"
      },
      "source": [
        "all_nan = list(null_view[-12:].index)\n",
        "all_nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Z4-Zz8H7ULED"
      },
      "source": [
        "indexes = df.loc[pd.isnull(df[['JobSatisfaction', 'EnvironmentSatisfaction', 'WorkLifeBalance']]).any(1), :].index.values\n",
        "print(f'Number indexes with missing data: {len(indexes)}')\n",
        "print(indexes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YltBUeLNULED"
      },
      "source": [
        "df = df.drop(df.index[indexes])\n",
        "time_df = time_df.drop(time_df.index[indexes])\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "time_df.reset_index(drop=True, inplace=True)\n",
        "print(df.shape)\n",
        "print(time_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QABApJauULEE"
      },
      "source": [
        "# NaN ML imputation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "qQUCwAZGULEE"
      },
      "source": [
        "def nan_predict(df,\n",
        "                skip_features_from_prediction_where_percent_missing_data_more_than = 100,\n",
        "                include_features_as_predictors_where_perc_missing_data_less_than = 50,\n",
        "                apply_fast_predictor_where_missing_data_less_than_percent = 100,\n",
        "                use_n_rows_for_train_not_more_than = 1000000000,    #  If your dataframe is large\n",
        "                randomizedSearchCV_iter_plus_perc_missing_data = 10,\n",
        "                n_estimators_parameter_for_LightGBM = 2000,\n",
        "                target_feature = None,   # For prediction at the end\n",
        "                ): \n",
        "    \n",
        "    import random\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "\n",
        "    # Disabling warnings\n",
        "    import sys\n",
        "    import warnings\n",
        "    if not sys.warnoptions:\n",
        "        warnings.simplefilter(\"ignore\")\n",
        "\n",
        "\n",
        "    from lightgbm import LGBMClassifier\n",
        "    from lightgbm import LGBMRegressor\n",
        "    from sklearn.model_selection import RandomizedSearchCV\n",
        "    from sklearn.model_selection import ShuffleSplit\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    from sklearn.metrics import f1_score\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    \n",
        "    \n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    %matplotlib inline\n",
        "    \n",
        "    \n",
        "\n",
        "    global counter_all_predicted_values\n",
        "    counter_all_predicted_values = 0\n",
        "    \n",
        "    global numeric_features\n",
        "    numeric_features = []\n",
        "    \n",
        "    global best_params\n",
        "    \n",
        "    \n",
        "    PARAMS  =  {'num_leaves': [12, 50, 120, 200, 300, 400, 500],   #np.arange(200, 600, step=100),\n",
        "                'max_depth': [4, 8, 12, 16],\n",
        "                'learning_rate': [0.001, 0.01, 0.1],\n",
        "                'n_estimators': [n_estimators_parameter_for_LightGBM],\n",
        "                'subsample': [0.1, 0.3, 0.5],\n",
        "                'feature_fraction': [0.1, 0.3, 0.5],\n",
        "                'bagging_fraction': [0.1, 0.3, 0.5],\n",
        "                'bagging_seed': np.arange(1, 3, step=1),\n",
        "                'lambda_l1': [0.2],\n",
        "                'lambda_l2': [0.1],\n",
        "                'min_child_samples': np.arange(2, 6, step=2),\n",
        "                'min_split_gain': [0.0001, 0.001]\n",
        "               }\n",
        "    \n",
        "    \n",
        "    CV = ShuffleSplit(n_splits=2, test_size=0.25, random_state=0)\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    def NaN_info(df):\n",
        "        global null_view\n",
        "        try:\n",
        "            null_view = df[[col for col in df.columns if df[col].isna().sum() > 0]].isna().sum().sort_values(ascending = True)\n",
        "            null_view = pd.DataFrame(null_view, columns=['NANs'])\n",
        "            null_view[['PERCENT']] = null_view.NANs.apply(lambda x: round((x/len(df))*100, 2))\n",
        "            null_view[['TYPE']] = df.dtypes\n",
        "        except:\n",
        "            return null_view\n",
        "        return null_view\n",
        "    \n",
        "    \n",
        "    def numeric_features(df):\n",
        "        num_features = [feature for feature in df.columns if df[feature].dtype in ['int64', 'float64']]\n",
        "        return num_features\n",
        "    \n",
        "    \n",
        "    def integer_features(df):\n",
        "        global int_features\n",
        "        int_features = [feature for feature in df.columns if df[feature].dtype in ['int64']]\n",
        "        return int_features\n",
        "\n",
        "\n",
        "    def encoding(work_predictors, df):\n",
        "        feature_power = 0.5          # Skew handling\n",
        "        for j in work_predictors:\n",
        "            el_type = df[j].dtype\n",
        "            if el_type == 'object':\n",
        "                df[j].replace(np.nan, 'NoNoNo', inplace=True)\n",
        "                labelencoder = LabelEncoder()\n",
        "                df.loc[:, j] = labelencoder.fit_transform(df.loc[:, j])\n",
        "            else:\n",
        "                df[j] = df[j]**feature_power\n",
        "        return df, work_predictors\n",
        "\n",
        "\n",
        "    def hyperparms_tuning(CV, X_train, X_test, y_train, y_test, n_iter_for_RandomizedSearchCV, PARAMS, alg, scoring):\n",
        "        global best_params\n",
        "        global pred_test_lgb\n",
        "\n",
        "        lgbm = alg(random_state = 0)\n",
        "        lgbm_randomized = RandomizedSearchCV(estimator=lgbm, \n",
        "                                            param_distributions=PARAMS, \n",
        "                                            n_iter=n_iter_for_RandomizedSearchCV, \n",
        "                                            scoring=scoring, \n",
        "                                            cv=CV, \n",
        "                                            verbose=0,\n",
        "                                            n_jobs = -1)\n",
        "\n",
        "        lgbm_randomized.fit(X_train, y_train)\n",
        "        \n",
        "        best_params = lgbm_randomized.best_params_\n",
        "        pred_test_lgb = lgbm_randomized.predict(X_test)\n",
        "        return best_params, pred_test_lgb\n",
        "\n",
        "    \n",
        "    def predict_regressor(best_params, X, y, miss_df):\n",
        "        print('Best parameters:')\n",
        "        print(best_params)\n",
        "        print('')\n",
        "        global pred_miss\n",
        "        lgbm = LGBMRegressor(**best_params, n_jobs=-1, random_state=0)\n",
        "        lgbm = lgbm.fit(X, y)\n",
        "        pred_miss = list(lgbm.predict(miss_df))\n",
        "        print('-------------------------------')\n",
        "        print(f\"The first 100 predicted missing values: \\n{pred_miss[:100]}\")\n",
        "        return pred_miss\n",
        "\n",
        "\n",
        "    def predict_classifier(best_params, X, y, miss_df):\n",
        "        print('Best parameters:')\n",
        "        print(best_params)\n",
        "        print('')\n",
        "        global pred_miss\n",
        "        lgbm = LGBMClassifier(**best_params, n_jobs=-1, random_state=0)\n",
        "        lgbm = lgbm.fit(X, y)\n",
        "        pred_miss = list(lgbm.predict(miss_df))\n",
        "        print('-------------------------------')\n",
        "        print(f\"The first 100 predicted missing values: \\n{pred_miss[:100]}\")\n",
        "        return pred_miss\n",
        "    \n",
        "    \n",
        "    def imput_missing_value_to_main_df(df, miss_indeces, pred_miss, el):\n",
        "        counter = 0\n",
        "        for idx in miss_indeces:\n",
        "            df.loc[idx, el] = pred_miss[counter]\n",
        "            counter += 1\n",
        "        return df\n",
        "    \n",
        "    \n",
        "    \n",
        "    # Go)\n",
        "\n",
        "    plt.figure(figsize=(20, 5))\n",
        "    sns.heatmap(df.isnull(), cbar=False)\n",
        "    \n",
        "    \n",
        "    print(NaN_info(df))\n",
        "    print('\\n\\n\\n')\n",
        "    \n",
        "    all_features = list(df.columns)\n",
        "    df_indeces = list(df.index)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    \n",
        "    integer_features(df)\n",
        "\n",
        "    delete_miss_features = list(\n",
        "        (null_view.loc[null_view['PERCENT'] > skip_features_from_prediction_where_percent_missing_data_more_than]).index)\n",
        "    print(f'Exclude from the prediction, because missing data more than \\\n",
        "    {skip_features_from_prediction_where_percent_missing_data_more_than}% :\\n{delete_miss_features}')\n",
        "    print('')\n",
        "    all_miss_features = list(null_view.index)\n",
        "\n",
        "    for delete_feature in delete_miss_features:\n",
        "        all_miss_features.remove(delete_feature)\n",
        "        \n",
        "    \n",
        "    if target_feature in all_miss_features:  # moving target_feature to end of the prediction\n",
        "        all_miss_features.append(all_miss_features.pop(all_miss_features.index(target_feature)))\n",
        "        \n",
        "    \n",
        "    for el in all_miss_features:\n",
        "        print('\\n\\n\\n\\n')\n",
        "        \n",
        "        # select features as predictors\n",
        "        NaN_info(df)\n",
        "        lot_of_miss_features = list(\n",
        "            (null_view.loc[null_view['PERCENT'] > include_features_as_predictors_where_perc_missing_data_less_than]).index)\n",
        "        now_predictors = list(set(all_features)-set(lot_of_miss_features))\n",
        "        work_predictors = list(set(now_predictors) - set([el]))\n",
        "\n",
        "        \n",
        "        # missing data (data for prediction)\n",
        "        miss_indeces = list((df[pd.isnull(df[el])]).index)\n",
        "        miss_df = df.iloc[miss_indeces][:]\n",
        "        miss_df = miss_df[work_predictors]\n",
        "        encoding(work_predictors, df=miss_df)\n",
        "\n",
        "        \n",
        "        # data without NaN rows (X data for train, evaluation of model)\n",
        "        work_indeces = list(set(df_indeces) - set(miss_indeces))\n",
        "        if len(work_indeces) > use_n_rows_for_train_not_more_than:\n",
        "            randomlist = random.sample(range(0, len(work_indeces)), use_n_rows_for_train_not_more_than)\n",
        "            work_indeces = [work_indeces[i] for i in randomlist]\n",
        "        \n",
        "        work_df = df.iloc[work_indeces][:] \n",
        "        encoding(work_predictors, df=work_df)\n",
        "        X = work_df[work_predictors]\n",
        "        y = work_df[el]\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "\n",
        "        \n",
        "        # Info\n",
        "        feature_type = df[el].dtypes\n",
        "        percent_missing_data = null_view['PERCENT'][el]\n",
        "        print(f'Feature: {el},   type: {feature_type},   missing values: {percent_missing_data}%\\n')    \n",
        "        print(f'Shape for train dataframe: {(X.shape)}')\n",
        "        print(f'Unused features as predictors, because missing data more than {include_features_as_predictors_where_perc_missing_data_less_than}% :')\n",
        "        print(lot_of_miss_features)\n",
        "        print('')\n",
        "        \n",
        "        \n",
        "        # PREDICTIONS\n",
        "        if percent_missing_data < apply_fast_predictor_where_missing_data_less_than_percent:\n",
        "            \n",
        "            # FAST Predictions without tuning hyperparameters\n",
        "            \n",
        "            print('FAST prediction without tuning hyperparameters\\n')\n",
        "            best_params = {}\n",
        "            if feature_type == 'object' or feature_type == 'bool':\n",
        "                print('FAST CLASSIFIER:')\n",
        "                labelencoder = LabelEncoder()\n",
        "                y_train = labelencoder.fit_transform(y_train)\n",
        "                y_test = labelencoder.fit_transform(y_test)\n",
        "                lgbm = LGBMClassifier(n_jobs=-1, random_state=0)\n",
        "                lgbm = lgbm.fit(X_train, y_train)\n",
        "                pred_test_lgb_FAST = lgbm.predict(X_test)\n",
        "                accuracy = accuracy_score(y_test, pred_test_lgb_FAST)\n",
        "                print('Evaluations:')\n",
        "                print(f'first 10 y_test: {y_test[:10]}')\n",
        "                print(f'first 10 y_pred: {pred_test_lgb_FAST[:10]}\\n')\n",
        "                f1 = f1_score(y_test, pred_test_lgb_FAST, average='weighted')\n",
        "                print(f'accuracy_score:      {accuracy}')\n",
        "                print(f'f1_score (weighted): {f1}')\n",
        "                \n",
        "                predict_classifier(best_params, X, y, miss_df)\n",
        "                counter_all_predicted_values += len(miss_indeces)\n",
        "                imput_missing_value_to_main_df(df, miss_indeces, pred_miss, el)\n",
        "\n",
        "            elif feature_type == 'float64' or feature_type == 'int64':\n",
        "                print('FAST REGRESSOR:')\n",
        "                \n",
        "                lgbm = LGBMRegressor(n_jobs=-1, random_state=0)\n",
        "                lgbm = lgbm.fit(X_train, np.log1p(y_train))\n",
        "                pred_test_lgb_FAST = lgbm.predict(X_test)\n",
        "                pred_test_lgb_FAST = np.expm1(pred_test_lgb_FAST)\n",
        "                MAE = mean_absolute_error(y_test,pred_test_lgb_FAST)\n",
        "                y_te = list(round(y_test[:10], 1))\n",
        "                y_pred = list(np.round(pred_test_lgb_FAST[:10], 1))\n",
        "                print('Evaluations:')\n",
        "                print(f'first 10 y_test: {y_te}')\n",
        "                print(f'first 10 y_pred: {y_pred}\\n')\n",
        "                print(f'mean_absolute_error: {MAE}')\n",
        "                print(f'mean for {el}: {df[el].mean()}')\n",
        "                \n",
        "                predict_regressor(best_params, X, y, miss_df)\n",
        "                counter_all_predicted_values += len(miss_indeces)\n",
        "                imput_missing_value_to_main_df(df, miss_indeces, pred_miss, el)\n",
        "\n",
        "            else:\n",
        "                print(f\"unprocessed feature: {el} - {feature_type} type\")\n",
        "                \n",
        "                  \n",
        "        else:\n",
        "            \n",
        "            # ADVANCED Predictions with tuning hyperparameters\n",
        "            \n",
        "            n_iter_for_RandomizedSearchCV = int(randomizedSearchCV_iter_plus_perc_missing_data + percent_missing_data * 1)\n",
        "            print(f'Iteration for RandomizedSearchCV: {n_iter_for_RandomizedSearchCV}\\n')\n",
        "            \n",
        "            if feature_type == 'object' or feature_type == 'bool':\n",
        "                print('ADVANCED CLASSIFIER:')\n",
        "                labelencoder = LabelEncoder()\n",
        "                y_train = labelencoder.fit_transform(y_train)\n",
        "                y_test = labelencoder.fit_transform(y_test)\n",
        "                hyperparms_tuning(CV, X_train, X_test, y_train, y_test, n_iter_for_RandomizedSearchCV, PARAMS, alg=LGBMClassifier, scoring='f1_weighted')\n",
        "                accuracy = accuracy_score(y_test, pred_test_lgb)\n",
        "                print('Evaluations:')\n",
        "                print(f'first 10 y_test: {y_test[:10]}')\n",
        "                print(f'first 10 y_pred: {pred_test_lgb[:10]}\\n')\n",
        "                f1 = f1_score(y_test, pred_test_lgb, average='weighted')\n",
        "                print(f'accuracy_score:      {accuracy}')\n",
        "                print(f'f1_score (weighted): {f1}')\n",
        "                \n",
        "                predict_classifier(best_params, X, y, miss_df)\n",
        "                counter_all_predicted_values += len(miss_indeces)\n",
        "                imput_missing_value_to_main_df(df, miss_indeces, pred_miss, el)\n",
        "\n",
        "            elif feature_type == 'float64' or feature_type == 'int64':\n",
        "                print('ADVANCED REGRESSOR:')\n",
        "                hyperparms_tuning(CV, X_train, X_test, y_train, y_test, n_iter_for_RandomizedSearchCV, PARAMS, alg=LGBMRegressor, scoring='neg_mean_squared_error')\n",
        "                MAE = mean_absolute_error(y_test,pred_test_lgb)\n",
        "                y_te = list(round(y_test[:10], 1))\n",
        "                y_pred = list(np.round(pred_test_lgb[:10], 1))\n",
        "                print('Evaluations:')\n",
        "                print(f'first 10 y_test: {y_te}')\n",
        "                print(f'first 10 y_pred: {y_pred}\\n')\n",
        "                print(f'mean_absolute_error: {MAE}')\n",
        "                print(f'mean for {el}: {df[el].mean()}')\n",
        "                \n",
        "                predict_regressor(best_params, X, y, miss_df)\n",
        "                counter_all_predicted_values += len(miss_indeces)\n",
        "                imput_missing_value_to_main_df(df, miss_indeces, pred_miss, el)\n",
        "\n",
        "            else:\n",
        "                print(f\"unprocessed feature: {el} - {feature_type} type\")\n",
        "        \n",
        "        plt.figure(figsize=(20, 5))\n",
        "        sns.heatmap(df.isnull(), cbar=False)\n",
        "\n",
        "        \n",
        "    for feature in int_features:\n",
        "        df[[feature]] = df[[feature]].astype('int64')\n",
        "        \n",
        "    df.index = df_indeces\n",
        "\n",
        "    print('\\n\\n\\n')\n",
        "    print(f'These features have not been processed, because missing data more than {skip_features_from_prediction_where_percent_missing_data_more_than}%')\n",
        "    print(NaN_info(df))\n",
        "    print('\\n\\n\\n')\n",
        "    print(f'{counter_all_predicted_values} values have been predicted and replaced')\n",
        "    print('\\n')\n",
        "    \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BWywo-FjULEN"
      },
      "source": [
        "nan_predict(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmeIGeFkULEU"
      },
      "source": [
        "# To int"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NZsmxjDwULEV"
      },
      "source": [
        "integer  = ['TotalWorkingYears', 'EnvironmentSatisfaction', 'JobSatisfaction', \n",
        "            'WorkLifeBalance', 'NumCompaniesWorked']\n",
        "for col in integer:\n",
        "    df[[col]] = df[[col]].astype('int64')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "R4uUWUhLULEV"
      },
      "source": [
        "for el in list(df.columns):\n",
        "    print(f'======================= {el} =======================')\n",
        "    print(df[el].value_counts(dropna=False))\n",
        "    print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DIYYtPJAULEW"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "sns.set(font_scale=1.5)\n",
        "sns.set_style(style='white') \n",
        "\n",
        "time_df[['Attrition']] = df[['Attrition']]\n",
        "\n",
        "for el in time_df.columns:\n",
        "    plot_data = time_df[['Attrition', el]]\n",
        "    try:\n",
        "        g = sns.pairplot(plot_data, hue='Attrition', palette='Set1', height=10, aspect=2)\n",
        "        \n",
        "        handles = g._legend_data.values()\n",
        "        labels = g._legend_data.keys()\n",
        "        g.fig.legend(handles=handles, labels=labels, loc='upper center', ncol=1)\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VBRDYlwwULEW"
      },
      "source": [
        "def categorical_features(df):\n",
        "    global cat_features\n",
        "    cat_features = [feature for feature in df.columns if df[feature].dtype in ['object']]\n",
        "    return cat_features\n",
        "\n",
        "categorical_features(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_oy2sG0GULEW"
      },
      "source": [
        "# sns.set_palette('twilight_shifted')\n",
        "for el in cat_features:\n",
        "    plot_data = df[['Attrition', el]]\n",
        "    try:\n",
        "        plt.figure(figsize=(20,10))\n",
        "        sns.countplot(x=plot_data[el], hue='Attrition', data=plot_data, palette='winter_r')\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "6M5HdWJEULEX"
      },
      "source": [
        "print('Impact of Performance Rating')\n",
        "print('\\n\\n')\n",
        "\n",
        "print('PerformanceRating == 4 (The Highest)')\n",
        "print('')\n",
        "a = df.loc[(df['Attrition'] == 'Yes') & (df['PerformanceRating'] == 4)]\n",
        "print(f'Number of Dismissed: \\t\\t\\t{len(a)}')\n",
        "print(f'Average Age: \\t\\t\\t\\t{a.Age.mean()}')\n",
        "print(f'Average Monthly Income: \\t\\t{a.MonthlyIncome.mean()}')\n",
        "print(f'Average Years at Company: \\t\\t{a.YearsAtCompany.mean()}')\n",
        "print(f'Average Years with Current Manager:\\t{a.YearsWithCurrManager.mean()}')\n",
        "print('\\n\\n')\n",
        "\n",
        "\n",
        "print('PerformanceRating == 3 (The lowest)')\n",
        "print('')\n",
        "b = df.loc[(df['Attrition'] == 'Yes') & (df['PerformanceRating'] == 3)]\n",
        "print(f'Number of Dismissed: \\t\\t\\t{len(b)}')\n",
        "print(f'Average Age: \\t\\t\\t\\t{b.Age.mean()}')\n",
        "print(f'Average Monthly Income: \\t\\t{b.MonthlyIncome.mean()}')\n",
        "print(f'Average Years at Company: \\t\\t{b.YearsAtCompany.mean()}')\n",
        "print(f'Average Years with Current Manager:\\t{b.YearsWithCurrManager.mean()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "iCDVpyMNULEX"
      },
      "source": [
        "print('Dismissals with Performance Rating and overtime (avg_work_day >= 10)')\n",
        "print('\\n\\n')\n",
        "\n",
        "print('PerformanceRating == 4 (The Highest)')\n",
        "print('')\n",
        "a = df.loc[(df['Attrition'] == 'Yes') & (df['avg_work_day'] >= 10) & (df['PerformanceRating'] == 4)]\n",
        "print(f'Number of Dismissed: \\t\\t\\t{len(a)}')\n",
        "print(f'Average Age: \\t\\t\\t\\t{a.Age.mean()}')\n",
        "print(f'Average Monthly Income: \\t\\t{a.MonthlyIncome.mean()}')\n",
        "print(f'Average Years at Company: \\t\\t{a.YearsAtCompany.mean()}')\n",
        "print(f'Average Years with Current Manager:\\t{a.YearsWithCurrManager.mean()}')\n",
        "print('\\n\\n')\n",
        "\n",
        "\n",
        "print('PerformanceRating == 3 (The lowest)')\n",
        "print('')\n",
        "b = df.loc[(df['Attrition'] == 'Yes') & (df['avg_work_day'] >= 10) & (df['PerformanceRating'] == 3)]\n",
        "print(f'Number of Dismissed: \\t\\t\\t{len(b)}')\n",
        "print(f'Average Age: \\t\\t\\t\\t{b.Age.mean()}')\n",
        "print(f'Average Monthly Income: \\t\\t{b.MonthlyIncome.mean()}')\n",
        "print(f'Average Years at Company: \\t\\t{b.YearsAtCompany.mean()}')\n",
        "print(f'Average Years with Current Manager:\\t{b.YearsWithCurrManager.mean()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w3Vb-DOULEX"
      },
      "source": [
        "# Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uSPJKJqAULEY"
      },
      "source": [
        "categorical_features(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZToTLXaxULEY"
      },
      "source": [
        "for el in categorical_features(df):\n",
        "    print(f'======================= {el} =======================')\n",
        "    print(df[el].value_counts(dropna=False))\n",
        "    print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZeDh02IyULEY"
      },
      "source": [
        "change = {\n",
        "    'No': 0,\n",
        "    'Yes': 1\n",
        "}\n",
        "\n",
        "df['Attrition'] = df['Attrition'].map(change)\n",
        "df['Attrition'] = df['Attrition'].astype('int64')\n",
        "df['Attrition'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fbokuSnXULEZ"
      },
      "source": [
        "change = {\n",
        "    'Non-Travel': 0,\n",
        "    'Travel_Rarely': 1,\n",
        "    'Travel_Frequently': 2\n",
        "}\n",
        "\n",
        "df['BusinessTravel'] = df['BusinessTravel'].map(change)\n",
        "df['BusinessTravel'] = df['BusinessTravel'].astype('int64')\n",
        "df['BusinessTravel'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Wq20HkvTULEZ"
      },
      "source": [
        "# change = {\n",
        "#     'Research & Development': 0,\n",
        "#     'Sales': 1,\n",
        "#     'Human Resources': 2\n",
        "# }\n",
        "\n",
        "# df['Department'] = df['Department'].map(change)\n",
        "# df['Department'] = df['Department'].astype('int64')\n",
        "# df['Department'].unique()\n",
        "\n",
        "\n",
        "dum_df = pd.get_dummies(df, columns=['Department'])\n",
        "df =pd.concat([dum_df])\n",
        "df[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "S0lDF6hoULEZ"
      },
      "source": [
        "change = {\n",
        "    'Other': 0,\n",
        "    'Life Sciences': 1,\n",
        "    'Medical': 2,\n",
        "    'Marketing': 3,\n",
        "    'Technical Degree': 4,\n",
        "    'Human Resources': 5,\n",
        "}\n",
        "\n",
        "df['EducationField'] = df['EducationField'].map(change)\n",
        "df['EducationField'] = df['EducationField'].astype('int64')\n",
        "df['EducationField'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BuPzjLjNULEa"
      },
      "source": [
        "# change = {\n",
        "#     'Sales Executive': 0,\n",
        "#     'Research Scientist': 1,\n",
        "#     'Laboratory Technician': 2,\n",
        "#     'Manufacturing Director': 3,\n",
        "#     'Healthcare Representative': 4,\n",
        "#     'Manager': 5,\n",
        "#     'Sales Representative': 6,\n",
        "#     'Research Director': 7,\n",
        "#     'Human Resources': 8,\n",
        "# }\n",
        "\n",
        "\n",
        "# df['JobRole'] = df['JobRole'].map(change)\n",
        "# df['JobRole'] = df['JobRole'].astype('int64')\n",
        "# df['JobRole'].unique()\n",
        "\n",
        "\n",
        "dum_df = pd.get_dummies(df, columns=['JobRole'])\n",
        "df =pd.concat([dum_df])\n",
        "df[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QbckfWEpULEa"
      },
      "source": [
        "change = {\n",
        "    'Male': 0,\n",
        "    'Female': 1,\n",
        "}\n",
        "\n",
        "df['Gender'] = df['Gender'].map(change)\n",
        "df['Gender'] = df['Gender'].astype('int64')\n",
        "df['Gender'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BPqRrZFAULEa"
      },
      "source": [
        "change = {\n",
        "    'Single': 0,\n",
        "    'Divorced': 1,\n",
        "    'Married': 2\n",
        "}\n",
        "\n",
        "df['MaritalStatus'] = df['MaritalStatus'].map(change)\n",
        "df['MaritalStatus'] = df['MaritalStatus'].astype('int64')\n",
        "df['MaritalStatus'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8d0Q9lcrULEb"
      },
      "source": [
        "desc = pd.DataFrame()\n",
        "a = list(df.columns)\n",
        "for el in a:\n",
        "    uniq = df[el].unique()\n",
        "    desc.loc[el, \"values\"] = str(uniq)\n",
        "\n",
        "desc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JKIk6v84ULEb"
      },
      "source": [
        "general_dism = df.loc[df['Attrition'] == 1]\n",
        "undesirable_dism = df.loc[(df['Attrition'] == 1) & (df['JobInvolvement'] >= 3) & (df['PerformanceRating'] == 4)]\n",
        "\n",
        "for col in df.columns:\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.title(col)\n",
        "    plt.scatter(general_dism.index, general_dism[col], label=\"general dismissed\", color='blue')\n",
        "    plt.scatter(undesirable_dism.index, undesirable_dism[col], label=\"undesirable dismissed\", color='red')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC4lp79tULEb"
      },
      "source": [
        "# Drop duplicate data => target leakage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNIXa39uULEc"
      },
      "source": [
        "![%D0%A1%D0%BD%D0%B8%D0%BC%D0%BE%D0%BA%20%D1%8D%D0%BA%D1%80%D0%B0%D0%BD%D0%B0%202021-03-04%20%D0%B2%2012.09.13.png](attachment:%D0%A1%D0%BD%D0%B8%D0%BC%D0%BE%D0%BA%20%D1%8D%D0%BA%D1%80%D0%B0%D0%BD%D0%B0%202021-03-04%20%D0%B2%2012.09.13.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tdyPl-GBULEc"
      },
      "source": [
        "df = df[:1600]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MOdhzRbULEc"
      },
      "source": [
        "# Statistic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uyxHJsSvULEd"
      },
      "source": [
        "still_working = df.loc[df['Attrition'] == 0]\n",
        "general_dism = df.loc[df['Attrition'] == 1]\n",
        "undesirable_dism = df.loc[(df['Attrition'] == 1) & (df['JobInvolvement'] >= 3) & (df['PerformanceRating'] == 4)]\n",
        "\n",
        "\n",
        "print('                                                company         still working       general dismissed   undesirable dismissed\\n')\n",
        "print(f'Number                                           {df.shape[0]}                 {still_working.shape[0]}                  {general_dism.shape[0]}                   {undesirable_dism.shape[0]}\\n')\n",
        "\n",
        "for col in df.columns:\n",
        "    comp = round(df[col].mean(), 2)\n",
        "    still = round(still_working[col].mean(), 2)\n",
        "    gen = round(general_dism[col].mean(), 2)\n",
        "    undes = round(undesirable_dism[col].mean(),2)\n",
        "    print(\"{:35s} {:20.2f} {:20.2f} {:20.2f} {:20.2f} \".format(col, comp, still, gen, undes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9d33Al2ULEd"
      },
      "source": [
        "## EDA for Managers\n",
        "'PerformanceRating', 'JobSatisfaction', 'JobInvolvement',     \n",
        "'EnvironmentSatisfaction', 'Attrition'(Dismissals), 'YearsAtCompany',     \n",
        "\n",
        "## EDA for employees\n",
        "'MonthlyIncome', 'StockOptionLevel', 'PercentSalaryHike', 'YearsWithCurrManager',    \n",
        "'Education', 'WorkLifeBalance', 'MaritalStatus',  'JobLevel', 'DistanceFromHome',     \n",
        "'TotalWorkingYears', 'TrainingTimesLastYear', 'BusinessTravel',    \n",
        "'EducationField', 'NumCompaniesWorked',  'YearsSinceLastPromotion',    \n",
        "'avg_work_day', 'num_day_off', \n",
        "\n",
        "\n",
        "## EDA for fun))   \n",
        "'in_avg', 'out_avg', 'Age', 'Gender', 'EmployeeID'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2Y6-rFhULEd"
      },
      "source": [
        "# ML Research"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KQcN9XtbULEe"
      },
      "source": [
        "import shap\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "features = [\n",
        "    # EDA for Managers\n",
        "    'PerformanceRating', 'JobSatisfaction', 'JobInvolvement',\n",
        "    'EnvironmentSatisfaction', 'Attrition', 'YearsAtCompany',\n",
        "    \n",
        "    # EDA for employees\n",
        "    'MonthlyIncome', 'StockOptionLevel', 'PercentSalaryHike', 'YearsWithCurrManager',\n",
        "    'Education', 'WorkLifeBalance', 'MaritalStatus', 'JobLevel', 'DistanceFromHome',\n",
        "    'TotalWorkingYears', 'TrainingTimesLastYear', 'BusinessTravel',\n",
        "    'EducationField', 'NumCompaniesWorked', 'YearsSinceLastPromotion',\n",
        "    'avg_work_day', 'num_day_off',\n",
        "\n",
        "    # EDA for fun\n",
        "    'in_avg', 'out_avg', 'Age', 'Gender', 'EmployeeID'\n",
        "    ]\n",
        "\n",
        "\n",
        "for col in features[:]:\n",
        "    df_research = df.copy()\n",
        "\n",
        "    target = [col]\n",
        "    predictors = list(set(list(df_research.columns)) - set(target))\n",
        "\n",
        "    X = df_research[predictors]\n",
        "    y = df_research[target]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "\n",
        "    print(f'{target}')\n",
        "    model = LGBMRegressor(random_state=0).fit(X_train, y_train)\n",
        "    explainer = shap.TreeExplainer(model)\n",
        "    shap_values = explainer.shap_values(X_test)\n",
        "    \n",
        "\n",
        "    plt.title(col)\n",
        "    plt.gcf().subplots_adjust()\n",
        "    shap.summary_plot(shap_values, X_test, max_display=X.shape[1], show=True, plot_size=(10, 12))\n",
        "    plt.savefig(\"shap_\"+col+\"_.png\")\n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvzCVe9nULEe"
      },
      "source": [
        "# Undesirable dismissions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vKMu556XULEe"
      },
      "source": [
        "print(df['JobInvolvement'].unique())\n",
        "print(df['PerformanceRating'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tla0F0kTULEf"
      },
      "source": [
        "undesirable = df.loc[(df['JobInvolvement'] >= 3) & (df['PerformanceRating'] == 4)]\n",
        "undesirable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qty4sbapULEf"
      },
      "source": [
        "df_research = undesirable.copy()\n",
        "\n",
        "target = ['Attrition']\n",
        "predictors = list(set(list(df_research.columns)) - set(target))\n",
        "\n",
        "X = df_research[predictors]\n",
        "y = df_research[target]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "\n",
        "print(f'{target}')\n",
        "model = LGBMRegressor(random_state=0).fit(X_train, y_train)\n",
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "\n",
        "plt.title('Attrition')\n",
        "plt.gcf().subplots_adjust()\n",
        "\n",
        "shap.summary_plot(shap_values, X_test, max_display=X.shape[1], show=True, plot_size=(10, 12))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.savefig(\"shap_\"+col+\"_.png\")\n",
        "plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or3fXmM_ULEf"
      },
      "source": [
        "# Deep understanding with PDP Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oLGl6r14ULEg"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from pdpbox import pdp\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "\n",
        "df_permutation_1 = df.copy()\n",
        "\n",
        "features = [\n",
        "    'PerformanceRating', 'JobSatisfaction', 'JobInvolvement',\n",
        "    'EnvironmentSatisfaction', 'YearsAtCompany',\n",
        "    \n",
        "    'MonthlyIncome', 'StockOptionLevel', 'PercentSalaryHike', 'YearsWithCurrManager',\n",
        "    'Education', 'WorkLifeBalance', 'MaritalStatus', 'JobLevel', 'DistanceFromHome',\n",
        "    'TotalWorkingYears', 'TrainingTimesLastYear', 'BusinessTravel',\n",
        "    'EducationField', 'NumCompaniesWorked', 'YearsSinceLastPromotion',\n",
        "    'avg_work_day', 'num_day_off',\n",
        "\n",
        "    'in_avg', 'out_avg', 'Age', 'Gender', 'EmployeeID'\n",
        "    ]\n",
        "\n",
        "target = ['Attrition']\n",
        "predictors = list(set(list(df_permutation_1.columns)) - set(target))\n",
        "\n",
        "X = df_permutation_1[predictors]\n",
        "y = df_permutation_1[target]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "\n",
        "\n",
        "model = LGBMRegressor(random_state=0).fit(X_train, y_train)\n",
        "\n",
        "for feature in features:\n",
        "    pdp_dist = pdp.pdp_isolate(model=model,\n",
        "                               dataset=X_test,\n",
        "                               model_features=X_test.columns, \n",
        "                               feature=feature)\n",
        "\n",
        "    pdp.pdp_plot(pdp_dist, feature)\n",
        "    plt.title('Attrition')  #\n",
        "    plt.savefig(\"pdp_\"+feature+\"_.png\", dpi=100)\n",
        "    plt.show()\n",
        "    plt.close()  #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TuZDJJHIULEg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}